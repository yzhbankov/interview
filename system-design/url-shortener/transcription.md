Yeah, let's start the first session. So this is my system design interview preparation. So this is my actually first time I'm doing this. So I am recording this for like tracking progress and like learning purpose. All right. So today is a system design interview. So the goal for today just to learn the design structure to understand how it's difficult and understand how I can like what I need to pay attention to. And yeah, so let's begin and start learning. So first of all, let's start with the task for today. So for today, I will need to system design the URL shortener. application. So this application is the application, this system that will allow you just to convert the long URLs to short URLs. And when user is using this short URLs that need to be redirected to the original URL. So this is the service I will build today. So what is my framework for today? What I will do? First of all, I will define requirements for the application like functional not functional so I need to make some estimations so I need to estimate how many servers, what database size, how many memory etc. What is the bandwidth of the system then I will need proceed with the API design, like which API need to be called to operate with the system. So maybe I just will go through the data model. So this is the database schema, decide like a scale, no scale, like maybe define some differences in relationships. Then I just proceed with the higher level design describing the kind of throwing boxes to to define the system, like what it will do, the components, how they will relate to each other. And at the end, I need to deep dive to any deep dive to one, two components and just to elaborate on them. So, and then touch the scaling issue. there are so four requirements it should be take not more than five minutes the estimations around five minutes API design it's kind of again five minutes the data model is 10 minutes high level design 10 minutes deep dive is 10 minutes and scaling is 5 minutes. So we get tough scale and let's begin and let's take a look what we can do with this. So let's start with the first requirements. So for design for URL shortener so we need to identify the functional requirements. The functional requirements is literally what functions our system will have. Like the first one is the short URL generator generation. So we, our system actually able to generate the unique shorter aliases. So we will provide like long original URL and we will get like the short URL in the response. So redirection from the system needs to redirect so when user will click to the short URL, it's shorted URL, it need to be redirected to the original URL. So we need to implement some house of the deletion functionality. So user should be able to delete these ads, because of different reasons, but should be able to delete this short link generation generated by our system. So user should be able to update this short URL. Then we should have expiry time, so just not to store these URLs for a long time. So non-functional requirements. So usually done functional requirements, they are around the availability. So the service should be highly available. So because even of the fraction of the second of downtime will result in URL or direction failures. Так что нужно очень высокую Вместе с by our system should be easily readable, distinguishable and typeable. So user should be like easily to type this URL, like so there shouldn't be like any special characters etc. So easily easy easy to read and type. latency. So the system should perform at low latency. Unpredictability. So this kind of security. security requirement, sorry, that's kind of security requirement. From a security standpoint, so these shortly generated, they should be unpredictable. So to ensure the next inline short URL is not serially produced. Things should be unpredictable. All right, so functional, non-functional requirements. So we do have like all the requirements. we can proceed with the estimations. The estimations. Like to proceed with the resource estimations, I need to understand like how the system will be used, how many users, and I will do kind of couple of the assumptions. Сначала, как система будет использовать, как много Aš kąčia ir iš will be 5 years. So we will not store these shorting URLs more than 5 years in our system. You want to provide the service and the daily active users. It's like 100 million of users for our service. And let's again assume that we will have like the 500 bytes for storing a shorting entry. The shorting entry. So this, now we need just to calculate the how many Let's start with the storage estimations. So the storage estimation, like storage estimation. So what we will have? So we will have like 200 million short on your per month. So for year it will be for 12 months. I just need to calculate like how many, what is the storage size. We need so this like 12 years, months, months. And we need to multiply this file 5 jų yra Nes, nes, n around the thick stirabytes. Thick stirabytes of the storage I will need. All right, so the total number of... Tai 200 miliją prieš mes jie per mes will be 12 billion of records in database. So we do have like expiration time, five years. So I have like this storage estimation. Then I just need to estimate the query rate, query rate estimation. The query rate estimation is we have like 200 million per day per month or per day per the romance. So we can multiply by 12, and divide to 365 days, and divide 24 hours, and divide next few let's multiply by a million. So we will get like around the 76, let's run it to bigger. So 77 requests per second. And this is like query rate, like, and we have like redirections. It's like 77. We have this ratio 1 to 100 and we will get like 77 hundreds of redirections per second. Directions per second. So we can estimate kind of the bandwidth estimations. And I feel like I am over the time with my estimations. So the bandwidth estimation is like we got for shortening requests, we got like 77x100. and redirections. It will be the same way, but multiplied by 100. So it will be like me, 24. It will be like 30. It will be around the 30... Calculator again, like, 97 by 500 and divide by 124. It's kind of 37, 37 kilobytes per second. for redirections it will be almost the same but like multiply by 100 and 8 beats why it's 8 beats So the 8 bits, 8 bits, I don't know why it's 8 bits. Yeah, we didn;t kilobytes per second, sorry megabytes per second. So this is a bandwidth estimation and we probably need to make memory estimation. So for the memory estimation it's like some of the records we need to keep in cache so to provide this low latency and like keeping in cache everything it will be probably not actually good approach because not all the URLs will be in use it's definitely we can take this parietal low and assume that like 20% of all the URLs else will be using 80% of time, so we can just, like take our how many we have, like we have 200 million. Six. Since reduction requests per second total will be one day. So we have like 7 redirections per second. So redirections per second. So we, this our system will use. So we will take like 300, 3,600 seconds by 24 hours and we got like around 0.7 billion of records and now this is like the total number. We just need to take 20% of the 7 billion of records, multiply by 500 bytes. And we got kind of like 67, around 67 gigabytes of memory. All right, so this is our estimations. We got four of these searching. I run over the time. So, all right, so now we need to proceed with the APIs. So, first of all, yeah, let me put it here, like estimations now we have APIs. So what kind of API we will have? So we will have an API for shorting URL, like let's build this like in the rest API way. So we will have a post request to, to like URL, shorting URL. So we will get this URL and we will provide like SD request body. It will be in this URL, what we will get. So we will get like first of all original URL. So we will get like expiry date. Tad ir kāds kā IPDef key or we stocking in headers. For simplicity we can put this IPDef key here that will our authorization. So this will be like the user unique identity file. All right, so this kind of not authorization yet. This will be required to do two. So this is our back shorten URL. Зараз ми вважаємо, як ред So, and as we can delete, so we need this delete method. So we can just provide here the original URL. So and we need to provide the API key. So we need to be authorized and to be able to delete like others. So the same could be for update the shorting URL. So we need the post-put. We need to delete. So the next one is the get method. So this actually method to redirect our users. So this will be like four basic APIs. Post to create, put to update, delete, and we need to redirect. All right, so we defined our APIs. So the next one is the data model. So this is our force data model. So the data model is what we are gonna store in the, in the, our storage. What kind of information we gonna store. So, we need to store first of all, again, like, original URL. So then we gonna need to store expiry date. Then we need to store user_herry. Then we need to store the shortened URL. So what kind of information do we need more? So it's probably can be, like this is all methods of information, like required probably can keep here some kind of ID, internal ID. And yeah, so it looks like we don't need anymore. Maybe for the bug purpose, we probably can like store kind of when it was changed, et cetera, but this will be really costly for us. So we have this user ID, so we can probably store in other like table or collection the users and this all the user information like this metadata for registered users. If we have these users and we adjust users in link. All right, so let's proceed with the, what we got next, high level design. HLD. So for highly level design what we need to, so we need to describe our diagram. So for this purpose I do need other tool. So this node path cannot serve this purpose. Let's find something. I need to draw a URL. It will be the easiest way. Yeah, it's perfect. So we will get the user. So this user, like we'll use our system. So we need to have the URL shortened service. Like let's start with the big blocks. URL, shortening service. So we got this. Then we need some storage. So where all this information will be. So this shortening service, like need to work with database. So it's like user field work with this service. So let's split this URL shortening service to the components. So we, for this URL shortening, so what we need is we discussed before, so we do need kind of cache. cache layer. So we need this service, let's do it another way. So we do have storage and we will have the cache. So the service will read the cache first and then read the storage if it will not find anything in cache. So as our system is heavily loaded, looks like it will not be only a single server, so it will be multiple servers. And that is why we need some load balancer. bet ir jiems iš visių they need like still do not, so the user will make the call to load balancer, load balancer will serve to proper, balancing to proper server. And so the servers will read from cache or storage. We'll do this in other way, let's do it this way. So between, so what is the server? So the server itself will be the web server and application server. So let me do this way. So we will have the web server and we will have the application server that will actually that will handle all the application logic. So, we do need the rate limiter because just to purpose to make our system more safe. So we will add on top of the web server. We need to add the rate limit. It can be like different strategies. But we need to limit some of the requests if the system cannot handle more. so we can pre-configure what can handle and what cannot handle. But yeah, this is it. So we will have this schema. So we have the load balancer that will define which server... So it can be like simple round robin balancing between all the servers or depends on how our system will scale. So it can be like based on the frequency can follow based on the region or based on the health of the server etc. Let's assume for the moment it will be working in simple round-trobin way. So yeah, let's discuss the workflow. So user is making requests to store data. So this request is going to load balancer. So this request is like balancing to some web server, so it's checking the rate limit. If it's not hit, then request is going to application server. Application server, like for redirections, they'll check the original URL in cache. If this in cache, it will not be found. So we will check in storage and then probably update the cache. If it will found and like return back redirection to your so you will be redirected to the proper link. So if anything will be hit here, like in rate limit, it will be returned the error or it will not be found. The other two will be returned like 404, that's nothing is found. Yeah, so the database as well, then cache can be distributed across like the different regions. So we can do this storage as the separate like read replicas and write. read Read Read Yeah, let's do this like in the Second is the next iteration of the So I do need to copy of these hld here and yeah so the storage itself can be can be done in this way so we will do like the right "beat public read" So this will be used for reading, everything else like will be used for... This for reading, and others for... Spreading out others for reading. I don't like it. I don't like it, I don't like it. So let's do it this way. Just join on the single umbrella. What's next? So I do have this HLD defined, and I almost have time, like deep dive. Deep dive. So we can deep dive into different components here. And we... I cannot find my deep dive into different components and let's dive into a component that is shortening our URLs and how this URL encoding will be like URL encoding. how we will exactly convert our original URL to short URL. So first of all, one of the functional requirements that it need to be readable. so we cannot use all the characters just to make these short URLs. So then let's exclude such kind of characters, characters like 0, 0, 0, 0, I and L. So we need to use... No, this is not actually a case. We don't need to exclude everything. So we can use base 58 instead of base 64 to exclude these special characters. and base 58 will actually exclude this lowercase l. Yeah, so let's use base 58. 58 just to convert. So we need every URL that will came to our system. That need to be applied like the ID. And this ID should be kind of like random ID. and this AD should be with the lens more than our system will have records. And as we know that our system will get like 12 billion records. It's not actually a really big number. So yeah, we can generate for each URL, we will generate base 10 ID. It will be taken from below these IDs, like in random way. Then we just need to convert this base 10 to base 58. So how this conversion will be done, it's kind of we can take any big number, like any Номбр и 74. So let's assume it will be 17 then we will get shorter. Then we will get like other We got the result, other result, and then we will do this again, divide by 58, and we got the example, etc. So we will proceed doing this, and we will get these IDs from the base 58 table, and Tad ir kā Then we need to make this conversion back. So we need to convert base 58 to base 10 to make the quick search in our database based on the ID and yeah so this will be pretty much the same so we will got this ID we will multiply 8 by the... its position, so it will be like... it will be 17... 17... multiply... 38... and we have the 6, 5858, and 1, and etc. and we will convert it back. Alright, so the deep dive into one of the components, actually you can be any component, and yeah, it's actually one of the areas I need to concentrate. So this scaling, oh man, yeah, I just not touched the database. Yeah, scaling, but I can't like, we can talk a little bit here for scaling. So for scalability, so we do need to, first of all, so we need to understand which database we need to use. So it looks like for our case, where we have a lot of data need to be horizontally scaled with three tree optics, et cetera. Looks like no scale database can be, like, would be a good choice for our purpose. so I can propose to take the MongoDB for this. So that's it's like supporting the horizontal scaling. Yeah, and like actually widely used in the production. So for this scalability, we know SQL this horizontal scaling. So we need to have these read write replicas. Write replicas. As we know that like the reading system is really heavy, so we need this. readability, the use of... All right, so let's take a look on the availability and scalability, scalability, etc. So for availability, it looks like we do need the distributed system, these many servers deployed in different regions, like if we are talking about kind of any less based systems or something like this, so we just need to run everything on different regions, different subnets. So we need to have the backups for our database so we can just restore anytime. So we need to have like the rate limits. So we need the load balancing. For scalability, we need the horizontal sharding of the database. So distributed database, consistent hashing. So we need the readability, for the readability requirement. So we introduced the base58 encoding. For latency, we do have this cache layer. We can store it in kind of memcache system. Yeah, this is predictability. So the IDs will be generated like randomly and so each new entry will be actually really separate entry. This is it. Thank you. Bye! 
